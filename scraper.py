import requests
import pandas as pd
import time
import os

# --- é…ç½®åŒº ---
BASE_URL = "https://cosylab.iiitd.edu.in/flavordb/entities_json?id="
SAVE_FILE = "flavordb_data.csv"
MAX_ID = 2600  # è®¾å®šä¸€ä¸ªè¾ƒå¤§çš„ä¸Šé™
BATCH_SIZE = 20 # æ¯æŠ“20ä¸ªå­˜ä¸€æ¬¡æ¡£

def get_last_id():
    """æ£€æŸ¥å·²ä¿å­˜çš„æ–‡ä»¶ï¼Œè·å–æœ€åä¸€ä¸ª ID"""
    if os.path.exists(SAVE_FILE):
        try:
            df = pd.read_csv(SAVE_FILE)
            if not df.empty:
                return int(df['id'].max())
        except:
            return 0
    return 0

def run_scraper():
    last_id = get_last_id()
    start_id = last_id + 1
    
    # è¯»å–å·²æœ‰æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºç©ºåˆ—è¡¨
    if os.path.exists(SAVE_FILE):
        results = pd.read_csv(SAVE_FILE).to_dict('records')
    else:
        results = []

    print(f"ğŸ”„ æ£€æŸ¥è¿›åº¦ï¼šå·²å®Œæˆè‡³ ID {last_id}ã€‚å‡†å¤‡ä» {start_id} å¼€å§‹...")

    if start_id > MAX_ID:
        print("âœ¨ æ‰€æœ‰æ•°æ®å·²æŠ“å–å®Œæ¯•ï¼")
        return

    for i in range(start_id, MAX_ID + 1):
        try:
            # å¢åŠ  headers æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œæ›´å®‰å…¨
            headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}
            response = requests.get(f"{BASE_URL}{i}", timeout=10, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                # æ ¸å¿ƒå­—æ®µæå–
                results.append({
                    "id": i,
                    "name": data.get("entity_alias_readable", "Unknown"),
                    "category": data.get("category_readable", "Unknown"),
                    "flavors": ", ".join(set(m.get("flavor_profile", "") for m in data.get("molecules", []) if m.get("flavor_profile")))
                })
                print(f"âœ… ID {i}: {data.get('entity_alias_readable', 'æœªçŸ¥é£Ÿæ')} æŠ“å–æˆåŠŸï¼")
            elif response.status_code == 404:
                print(f"â© ID {i} ç©ºç¼º (404)")
            
        except Exception as e:
            print(f"âŒ ID {i} é”™è¯¯: {e}")
            break # é‡åˆ°ä¸¥é‡é”™è¯¯ï¼ˆå¦‚æ–­ç½‘ï¼‰å…ˆåœæ­¢ï¼Œä¸‹æ¬¡è¿è¡Œä¼šè‡ªåŠ¨é‡è¿

        # åˆ†æ®µä¿å­˜
        if i % BATCH_SIZE == 0:
            pd.DataFrame(results).to_csv(SAVE_FILE, index=False)
            print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜è‡³ ID {i}")
            time.sleep(0.5) # ç»™æœåŠ¡å™¨å–˜å£æ°”

    pd.DataFrame(results).to_csv(SAVE_FILE, index=False)
    print("ğŸ æœ¬æ¬¡æŠ“å–ç»“æŸã€‚")

if __name__ == "__main__":
    run_scraper()
